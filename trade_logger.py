import json
import os
import threading
import time
import atexit
from datetime import datetime
from typing import Dict, List, Optional, Any
from utils.helpers import setup_logger

logger = setup_logger(__name__)

ML_FEATURE_SCHEMA = {
    'signal_features': {
        'confidence': {'type': 'float', 'required': True, 'description': 'ä¿¡è™Ÿä¿¡å¿ƒåº¦ (0-100)'},
        'expected_roi': {'type': 'float', 'required': True, 'description': 'é æœŸæ”¶ç›Šç‡ (%)'},
        'strategy': {'type': 'str', 'required': True, 'description': 'ç­–ç•¥åç¨± (ICT_SMC, etc.)'},
        'reason': {'type': 'str', 'required': True, 'description': 'é–‹å€‰ç†ç”±'},
        'market_structure': {'type': 'str', 'required': False, 'description': 'å¸‚å ´çµæ§‹ (bullish/bearish/neutral)'},
        'ob_score': {'type': 'float', 'required': False, 'description': 'è¨‚å–®å¡Šå¾—åˆ†'},
        'liquidity_grabbed': {'type': 'bool', 'required': False, 'description': 'æ˜¯å¦æŠ“å–æµå‹•æ€§'},
        'trend_15m': {'type': 'str', 'required': False, 'description': '15åˆ†é˜è¶¨å‹¢'},
        'trend_1h': {'type': 'str', 'required': False, 'description': '1å°æ™‚è¶¨å‹¢'}
    },
    'technical_indicators': {
        'macd': {'type': 'float', 'required': False, 'description': 'MACD å€¼'},
        'macd_signal': {'type': 'float', 'required': False, 'description': 'MACD ä¿¡è™Ÿç·š'},
        'macd_histogram': {'type': 'float', 'required': False, 'description': 'MACD æŸ±ç‹€åœ–'},
        'ema_9': {'type': 'float', 'required': False, 'description': '9é€±æœŸEMA'},
        'ema_21': {'type': 'float', 'required': False, 'description': '21é€±æœŸEMA'},
        'ema_50': {'type': 'float', 'required': False, 'description': '50é€±æœŸEMA'},
        'ema_200': {'type': 'float', 'required': False, 'description': '200é€±æœŸEMA'},
        'atr': {'type': 'float', 'required': False, 'description': 'å¹³å‡çœŸå¯¦ç¯„åœ'},
        'bollinger_upper': {'type': 'float', 'required': False, 'description': 'å¸ƒæ—å¸¶ä¸Šè»Œ'},
        'bollinger_middle': {'type': 'float', 'required': False, 'description': 'å¸ƒæ—å¸¶ä¸­è»Œ'},
        'bollinger_lower': {'type': 'float', 'required': False, 'description': 'å¸ƒæ—å¸¶ä¸‹è»Œ'},
        'rsi': {'type': 'float', 'required': False, 'description': 'ç›¸å°å¼·å¼±æŒ‡æ¨™'}
    },
    'price_position': {
        'current_price': {'type': 'float', 'required': True, 'description': 'ç•¶å‰åƒ¹æ ¼'},
        'distance_from_ema200': {'type': 'float', 'required': False, 'description': 'èˆ‡EMA200çš„è·é›¢'},
        'distance_from_ema200_pct': {'type': 'float', 'required': False, 'description': 'èˆ‡EMA200çš„è·é›¢ç™¾åˆ†æ¯”'}
    },
    'trade_parameters': {
        'entry_price': {'type': 'float', 'required': True, 'description': 'å…¥å ´åƒ¹æ ¼'},
        'stop_loss': {'type': 'float', 'required': False, 'description': 'æ­¢æåƒ¹æ ¼'},
        'take_profit': {'type': 'float', 'required': False, 'description': 'æ­¢ç›ˆåƒ¹æ ¼'},
        'leverage': {'type': 'float', 'required': True, 'description': 'æ§“æ¡¿å€æ•¸'},
        'margin': {'type': 'float', 'required': True, 'description': 'ä¿è­‰é‡‘'},
        'margin_percent': {'type': 'float', 'required': True, 'description': 'ä¿è­‰é‡‘ç™¾åˆ†æ¯”'}
    },
    'kline_data': {
        'entry_klines': {'type': 'list', 'required': False, 'description': 'é–‹å€‰æ™‚Kç·šå¿«ç…§ (æœ€è¿‘20æ ¹)'},
        'kline_history': {'type': 'list', 'required': False, 'description': 'æŒå€‰æœŸé–“å®Œæ•´Kç·šæ­·å²'}
    },
    'outcome_labels': {
        'outcome': {'type': 'str', 'required': True, 'description': 'äº¤æ˜“çµæœ (WIN/LOSS)'},
        'pnl_percent': {'type': 'float', 'required': True, 'description': 'æç›Šç™¾åˆ†æ¯”'},
        'max_favorable_excursion': {'type': 'float', 'required': True, 'description': 'æœ€å¤§æœ‰åˆ©æ³¢å‹• (%)'},
        'max_adverse_excursion': {'type': 'float', 'required': True, 'description': 'æœ€å¤§ä¸åˆ©æ³¢å‹• (%)'},
        'hit_take_profit': {'type': 'bool', 'required': True, 'description': 'æ˜¯å¦è§¸åŠæ­¢ç›ˆ'},
        'hit_stop_loss': {'type': 'bool', 'required': True, 'description': 'æ˜¯å¦è§¸åŠæ­¢æ'}
    }
}


class TradeLogger:
    """
    å¢å¼·çš„äº¤æ˜“æ—¥èªŒè¨˜éŒ„å™¨ - æ”¯æŒå®Œæ•´çš„ XGBoost æ©Ÿå™¨å­¸ç¿’æ•¸æ“šè¨˜éŒ„
    
    åŠŸèƒ½ï¼š
    1. è¨˜éŒ„é–‹å€‰æ™‚çš„å®Œæ•´ç‰¹å¾µæ•¸æ“šï¼ˆæŠ€è¡“æŒ‡æ¨™ã€Kç·šå¿«ç…§ã€ä¿¡è™Ÿç‰¹å¾µï¼‰
    2. è¨˜éŒ„å¹³å€‰æ™‚çš„å®Œæ•´æ­·å²æ•¸æ“šï¼ˆKç·šæ­·å²ã€MFE/MAEã€äº¤æ˜“çµæœï¼‰
    3. åˆä½µé–‹å€‰/å¹³å€‰æ•¸æ“šç”Ÿæˆå®Œæ•´çš„ ML è¨“ç·´æ¨£æœ¬
    4. ä¿å­˜åŸºæœ¬äº¤æ˜“è¨˜éŒ„å’Œ ML è¨“ç·´æ•¸æ“šåˆ°ä¸åŒæ–‡ä»¶
    5. æ™ºèƒ½ Flush æ©Ÿåˆ¶ï¼šæ¯ 10 ç­†äº¤æ˜“æˆ– 30 ç§’è‡ªå‹•ä¿å­˜
    6. æ•¸æ“šå®Œæ•´æ€§é©—è­‰ï¼šç¢ºä¿æ‰€æœ‰é–‹å€‰éƒ½æœ‰å°æ‡‰çš„å¹³å€‰
    7. çµ±è¨ˆè¿½è¹¤ï¼šè¨˜éŒ„å®Œæ•´æ€§ã€ç‰¹å¾µè¦†è“‹ç‡ç­‰
    """
    
    def __init__(self, log_file='trades.json', ml_file='ml_training_data.json', buffer_size=10, auto_flush_interval=30):
        """
        åˆå§‹åŒ–äº¤æ˜“æ—¥èªŒè¨˜éŒ„å™¨
        
        Args:
            log_file: åŸºæœ¬äº¤æ˜“è¨˜éŒ„æ–‡ä»¶
            ml_file: ML è¨“ç·´æ•¸æ“šæ–‡ä»¶
            buffer_size: ç·©è¡å€å¤§å°ï¼ˆå¤šå°‘æ¢è¨˜éŒ„å¾Œä¿å­˜ä¸€æ¬¡ï¼‰
            auto_flush_interval: è‡ªå‹• flush æ™‚é–“é–“éš”ï¼ˆç§’ï¼‰
        """
        self.log_file = log_file
        self.ml_file = ml_file
        self.pending_entries_file = 'ml_pending_entries.json'
        self.buffer_size = buffer_size
        self.auto_flush_interval = auto_flush_interval
        self.unsaved_count = 0
        self.last_flush_time = time.time()
        
        # çµ±è¨ˆæ•¸æ“š
        self.stats = {
            'total_entries': 0,
            'total_exits': 0,
            'complete_pairs': 0,
            'incomplete_pairs': 0,
            'total_flushes': 0,
            'last_flush_timestamp': None,
            'validation_errors': 0,
            'feature_coverage': {}
        }
        
        # åŠ è¼‰ç¾æœ‰è¨˜éŒ„
        self.trades = self.load_trades()
        
        # ML è¨“ç·´æ•¸æ“šçµæ§‹
        self.ml_data = self.load_ml_data()
        self.pending_entries = self.load_pending_entries()
        
        # æ›´æ–°çµ±è¨ˆæ•¸æ“š
        self.stats['incomplete_pairs'] = len(self.pending_entries)
        self.stats['complete_pairs'] = len(self.ml_data)
        
        # å•Ÿå‹•è‡ªå‹• flush ç·šç¨‹
        self._stop_auto_flush = threading.Event()
        self._auto_flush_thread = threading.Thread(target=self._auto_flush_worker, daemon=True)
        self._auto_flush_thread.start()
        
        # è¨»å†Šé€€å‡ºæ™‚å¼·åˆ¶ flush
        atexit.register(self._on_exit)
        
        logger.info(
            f"TradeLogger initialized: "
            f"trades={len(self.trades)}, "
            f"ml_samples={len(self.ml_data)}, "
            f"pending_entries={len(self.pending_entries)}, "
            f"auto_flush_interval={auto_flush_interval}s"
        )
    
    def _auto_flush_worker(self):
        """è‡ªå‹• flush å·¥ä½œç·šç¨‹ - æ¯ N ç§’æª¢æŸ¥ä¸¦ flush"""
        while not self._stop_auto_flush.is_set():
            try:
                time.sleep(self.auto_flush_interval)
                
                current_time = time.time()
                time_since_last_flush = current_time - self.last_flush_time
                
                if time_since_last_flush >= self.auto_flush_interval:
                    if self.unsaved_count > 0 or len(self.ml_data) > 0:
                        logger.debug(f"Auto-flush triggered (interval: {self.auto_flush_interval}s)")
                        self.flush()
                
            except Exception as e:
                logger.error(f"Error in auto-flush worker: {e}")
    
    def _on_exit(self):
        """ç¨‹åºé€€å‡ºæ™‚çš„æ¸…ç†å‡½æ•¸"""
        logger.info("TradeLogger shutting down, flushing all data...")
        self._stop_auto_flush.set()
        self.flush()
        logger.info("TradeLogger shutdown complete")
    
    def load_trades(self) -> List[Dict]:
        """åŠ è¼‰ç¾æœ‰äº¤æ˜“è¨˜éŒ„"""
        if os.path.exists(self.log_file):
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"Error loading trades: {e}")
                return []
        return []
    
    def load_ml_data(self) -> List[Dict]:
        """åŠ è¼‰ç¾æœ‰ ML è¨“ç·´æ•¸æ“š"""
        if os.path.exists(self.ml_file):
            try:
                with open(self.ml_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"Error loading ML data: {e}")
                return []
        return []
    
    def load_pending_entries(self) -> Dict[str, Dict]:
        """
        åŠ è¼‰å¾…è™•ç†çš„é–‹å€‰è¨˜éŒ„
        
        é€²ç¨‹é‡å•Ÿæ™‚å¾æ–‡ä»¶æ¢å¾©å¾…è™•ç†çš„é–‹å€‰è¨˜éŒ„ï¼Œé¿å…å­¤ç«‹äº¤æ˜“
        
        Returns:
            å¾…è™•ç†çš„é–‹å€‰è¨˜éŒ„å­—å…¸
        """
        if os.path.exists(self.pending_entries_file):
            try:
                with open(self.pending_entries_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    logger.info(f"Loaded {len(data)} pending entries from {self.pending_entries_file}")
                    return data
            except Exception as e:
                logger.error(f"Error loading pending entries: {e}")
                return {}
        return {}
    
    def save_pending_entries(self):
        """
        ä¿å­˜å¾…è™•ç†çš„é–‹å€‰è¨˜éŒ„åˆ°æ–‡ä»¶
        
        ç¢ºä¿é‡å•Ÿå¾Œä¸æœƒä¸Ÿå¤±å¾…è™•ç†çš„é–‹å€‰è¨˜éŒ„
        """
        try:
            with open(self.pending_entries_file, 'w', encoding='utf-8') as f:
                json.dump(self.pending_entries, f, indent=2, ensure_ascii=False)
            logger.debug(f"Saved {len(self.pending_entries)} pending entries to {self.pending_entries_file}")
        except Exception as e:
            logger.error(f"Error saving pending entries: {e}")
    
    def save_trades(self):
        """ä¿å­˜äº¤æ˜“è¨˜éŒ„åˆ°æ–‡ä»¶"""
        try:
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(self.trades, f, indent=2, ensure_ascii=False)
            logger.info(f"Saved {len(self.trades)} trades to {self.log_file}")
            self.unsaved_count = 0
        except Exception as e:
            logger.error(f"Error saving trades: {e}")
    
    def save_ml_data(self):
        """ä¿å­˜ ML è¨“ç·´æ•¸æ“šåˆ°å–®ç¨æ–‡ä»¶"""
        try:
            with open(self.ml_file, 'w', encoding='utf-8') as f:
                json.dump(self.ml_data, f, indent=2, ensure_ascii=False)
            logger.info(f"âœ… Saved {len(self.ml_data)} ML training samples to {self.ml_file}")
        except Exception as e:
            logger.error(f"Error saving ML data: {e}")
    
    def validate_entry_data(self, trade_data: Dict) -> tuple[bool, List[str]]:
        """
        é©—è­‰é–‹å€‰æ•¸æ“šçš„å®Œæ•´æ€§å’Œæ­£ç¢ºæ€§
        
        Args:
            trade_data: é–‹å€‰æ•¸æ“šå­—å…¸
            
        Returns:
            (is_valid, missing_fields)
        """
        missing_fields = []
        warnings = []
        
        # æª¢æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ['symbol', 'side', 'entry_price', 'quantity', 'leverage', 'margin', 'confidence']
        for field in required_fields:
            if field not in trade_data or trade_data[field] is None:
                missing_fields.append(field)
        
        # æª¢æŸ¥æ•¸æ“šé¡å‹å’Œç¯„åœ
        if 'confidence' in trade_data:
            confidence = trade_data['confidence']
            if not isinstance(confidence, (int, float)) or not (0 <= confidence <= 100):
                warnings.append(f"Invalid confidence value: {confidence}")
        
        if 'entry_price' in trade_data:
            if not isinstance(trade_data['entry_price'], (int, float)) or trade_data['entry_price'] <= 0:
                warnings.append(f"Invalid entry_price: {trade_data['entry_price']}")
        
        if 'leverage' in trade_data:
            if not isinstance(trade_data['leverage'], (int, float)) or trade_data['leverage'] <= 0:
                warnings.append(f"Invalid leverage: {trade_data['leverage']}")
        
        # è¨˜éŒ„è­¦å‘Š
        if warnings:
            logger.warning(f"Validation warnings for entry data: {warnings}")
            self.stats['validation_errors'] += 1
        
        is_valid = len(missing_fields) == 0
        
        if not is_valid:
            logger.error(f"Missing required fields in entry data: {missing_fields}")
            self.stats['validation_errors'] += 1
        
        return is_valid, missing_fields
    
    def validate_exit_data(self, trade_data: Dict) -> tuple[bool, List[str]]:
        """
        é©—è­‰å¹³å€‰æ•¸æ“šçš„å®Œæ•´æ€§å’Œæ­£ç¢ºæ€§
        
        Args:
            trade_data: å¹³å€‰æ•¸æ“šå­—å…¸
            
        Returns:
            (is_valid, missing_fields)
        """
        missing_fields = []
        warnings = []
        
        # æª¢æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ['trade_id', 'symbol', 'exit_price', 'pnl', 'pnl_percent']
        for field in required_fields:
            if field not in trade_data or trade_data[field] is None:
                missing_fields.append(field)
        
        # æª¢æŸ¥ trade_id æ˜¯å¦å­˜åœ¨æ–¼ pending_entries
        if 'trade_id' in trade_data:
            trade_id = trade_data['trade_id']
            if trade_id not in self.pending_entries:
                warnings.append(f"No matching entry record for trade_id: {trade_id}")
        
        # è¨˜éŒ„è­¦å‘Š
        if warnings:
            logger.warning(f"Validation warnings for exit data: {warnings}")
            self.stats['validation_errors'] += 1
        
        is_valid = len(missing_fields) == 0
        
        if not is_valid:
            logger.error(f"Missing required fields in exit data: {missing_fields}")
            self.stats['validation_errors'] += 1
        
        return is_valid, missing_fields
    
    def calculate_feature_coverage(self, entry_record: Dict) -> Dict[str, float]:
        """
        è¨ˆç®—ç‰¹å¾µè¦†è“‹ç‡
        
        Args:
            entry_record: é–‹å€‰è¨˜éŒ„
            
        Returns:
            ç‰¹å¾µè¦†è“‹ç‡å­—å…¸
        """
        coverage = {
            'signal_features': 0,
            'technical_indicators': 0,
            'price_position': 0,
            'kline_data': 0
        }
        
        signal_features = entry_record.get('signal_features', {})
        total_signal_features = len(ML_FEATURE_SCHEMA['signal_features'])
        present_signal_features = sum(1 for k in ML_FEATURE_SCHEMA['signal_features'].keys() if k in signal_features and signal_features[k] is not None)
        coverage['signal_features'] = (present_signal_features / total_signal_features * 100) if total_signal_features > 0 else 0
        
        total_tech_indicators = len(ML_FEATURE_SCHEMA['technical_indicators'])
        present_tech_indicators = sum(1 for k in ML_FEATURE_SCHEMA['technical_indicators'].keys() if k in signal_features and signal_features[k] is not None)
        coverage['technical_indicators'] = (present_tech_indicators / total_tech_indicators * 100) if total_tech_indicators > 0 else 0
        
        total_price_position = len(ML_FEATURE_SCHEMA['price_position'])
        present_price_position = sum(1 for k in ML_FEATURE_SCHEMA['price_position'].keys() if k in signal_features and signal_features[k] is not None)
        coverage['price_position'] = (present_price_position / total_price_position * 100) if total_price_position > 0 else 0
        
        has_entry_klines = 'entry_klines' in entry_record and entry_record['entry_klines']
        coverage['kline_data'] = 100 if has_entry_klines else 0
        
        return coverage
    
    def log_position_entry(self, trade_data: Dict, binance_client=None, timeframe='1m', is_virtual=False) -> str:
        """
        è¨˜éŒ„é–‹å€‰æ™‚çš„å®Œæ•´ç‰¹å¾µæ•¸æ“š
        
        Args:
            trade_data: äº¤æ˜“æ•¸æ“šå­—å…¸ï¼ŒåŒ…å«ï¼š
                - symbol: äº¤æ˜“å°
                - side: 'BUY' or 'SELL'
                - entry_price: å…¥å ´åƒ¹æ ¼
                - quantity: æ•¸é‡
                - stop_loss: æ­¢æåƒ¹æ ¼
                - take_profit: æ­¢ç›ˆåƒ¹æ ¼
                - leverage: æ§“æ¡¿
                - margin: ä¿è­‰é‡‘
                - margin_percent: ä¿è­‰é‡‘ç™¾åˆ†æ¯”
                - confidence: ä¿¡å¿ƒåº¦
                - expected_roi: é æœŸæ”¶ç›Š
                - strategy: ç­–ç•¥åç¨±
                - reason: é–‹å€‰ç†ç”±
                - metadata: ä¿¡è™Ÿçš„å®Œæ•´ metadataï¼ˆåŒ…å«æ‰€æœ‰æŠ€è¡“æŒ‡æ¨™ï¼‰
            binance_client: Binance å®¢æˆ¶ç«¯ï¼ˆç”¨æ–¼ç²å– K ç·šå¿«ç…§ï¼‰
            timeframe: æ™‚é–“æ¡†æ¶
            is_virtual: æ˜¯å¦ç‚ºè™›æ“¬å€‰ä½ï¼ˆé»˜èª Falseï¼‰
            
        Returns:
            trade_id: å”¯ä¸€çš„äº¤æ˜“ID
        """
        try:
            # é©—è­‰æ•¸æ“š
            is_valid, missing_fields = self.validate_entry_data(trade_data)
            if not is_valid:
                logger.error(f"Entry data validation failed, missing fields: {missing_fields}")
                return None
            
            # ç”Ÿæˆå”¯ä¸€çš„äº¤æ˜“ID
            timestamp = datetime.utcnow()
            trade_id = self._generate_trade_id(trade_data['symbol'], timestamp)
            
            # ç²å– K ç·šå¿«ç…§ï¼ˆæœ€è¿‘ 20 æ ¹ï¼‰
            entry_klines = []
            if binance_client:
                try:
                    entry_klines = self._fetch_klines_snapshot(
                        binance_client, 
                        trade_data['symbol'], 
                        timeframe, 
                        limit=20
                    )
                except Exception as e:
                    logger.warning(f"Failed to fetch klines snapshot for {trade_data['symbol']}: {e}")
            
            # å¾ metadata ä¸­æå–æŠ€è¡“æŒ‡æ¨™
            metadata = trade_data.get('metadata', {})
            
            # æ§‹å»ºå®Œæ•´çš„é–‹å€‰è¨˜éŒ„
            entry_record = {
                'trade_id': trade_id,
                'timestamp': timestamp.isoformat(),
                'symbol': trade_data.get('symbol', 'UNKNOWN'),
                'side': trade_data.get('side', 'BUY'),
                'entry_price': self._safe_float(trade_data.get('entry_price'), 0.0),
                'quantity': self._safe_float(trade_data.get('quantity'), 0.0),
                'stop_loss': self._safe_float(trade_data.get('stop_loss')),
                'take_profit': self._safe_float(trade_data.get('take_profit')),
                'leverage': self._safe_float(trade_data.get('leverage'), 1.0),
                'margin': self._safe_float(trade_data.get('margin'), 0.0),
                'margin_percent': self._safe_float(trade_data.get('margin_percent'), 0.0),
                'is_virtual': is_virtual,
                
                # ICT/SMC ä¿¡è™Ÿç‰¹å¾µ
                'signal_features': {
                    'confidence': self._safe_float(trade_data.get('confidence'), 0.0),
                    'expected_roi': self._safe_float(trade_data.get('expected_roi'), 0.0),
                    'strategy': trade_data.get('strategy', 'UNKNOWN'),
                    'reason': trade_data.get('reason', ''),
                    
                    # å¸‚å ´çµæ§‹ï¼ˆå¾ metadata æå–ï¼‰
                    'market_structure': metadata.get('market_structure', 'neutral'),
                    'ob_score': self._safe_float(metadata.get('ob_score')),
                    'liquidity_grabbed': metadata.get('liquidity_grabbed', False),
                    'trend_15m': metadata.get('trend_15m', 'neutral'),
                    'trend_1h': metadata.get('trend_1h', 'neutral'),
                    
                    # æŠ€è¡“æŒ‡æ¨™ï¼ˆç•¶ä¸‹å€¼ï¼‰
                    'macd': self._safe_float(metadata.get('macd')),
                    'macd_signal': self._safe_float(metadata.get('macd_signal')),
                    'macd_histogram': self._safe_float(metadata.get('macd_histogram')),
                    'ema_9': self._safe_float(metadata.get('ema_9')),
                    'ema_21': self._safe_float(metadata.get('ema_21')),
                    'ema_50': self._safe_float(metadata.get('ema_50')),
                    'ema_200': self._safe_float(metadata.get('ema_200')),
                    'atr': self._safe_float(metadata.get('atr')),
                    'bollinger_upper': self._safe_float(metadata.get('bollinger_upper')),
                    'bollinger_middle': self._safe_float(metadata.get('bollinger_middle')),
                    'bollinger_lower': self._safe_float(metadata.get('bollinger_lower')),
                    'rsi': self._safe_float(metadata.get('rsi')),
                    
                    # åƒ¹æ ¼ä½ç½®
                    'current_price': self._safe_float(metadata.get('current_price')),
                    'distance_from_ema200': self._calculate_distance_from_ema200(
                        metadata.get('current_price'),
                        metadata.get('ema_200')
                    ),
                    'distance_from_ema200_pct': self._calculate_distance_from_ema200_pct(
                        metadata.get('current_price'),
                        metadata.get('ema_200')
                    ),
                    
                    # å®Œæ•´çš„ metadata
                    'metadata': self._sanitize_metadata(metadata)
                },
                
                # é–‹å€‰æ™‚çš„ K ç·šå¿«ç…§ï¼ˆæœ€è¿‘ 20 æ ¹ï¼‰
                'entry_klines': entry_klines
            }
            
            # è¨ˆç®—ç‰¹å¾µè¦†è“‹ç‡
            coverage = self.calculate_feature_coverage(entry_record)
            self.stats['feature_coverage'] = coverage
            
            # æš«å­˜é–‹å€‰æ•¸æ“šï¼Œç­‰å¾…å¹³å€‰å¾Œåˆä½µ
            self.pending_entries[trade_id] = entry_record
            
            # æ›´æ–°çµ±è¨ˆ
            self.stats['total_entries'] += 1
            self.stats['incomplete_pairs'] = len(self.pending_entries)
            
            # ç«‹å³æŒä¹…åŒ–åˆ°æ–‡ä»¶ï¼Œé¿å…é€²ç¨‹é‡å•Ÿå°è‡´å­¤ç«‹äº¤æ˜“
            self.save_pending_entries()
            
            logger.info(
                f"ğŸ“¥ Logged position entry: {trade_id} ({trade_data.get('symbol', 'UNKNOWN')} {trade_data.get('side', 'BUY')}), "
                f"feature_coverage: {coverage}"
            )
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦ flushï¼ˆæ¯ buffer_size æ¢è¨˜éŒ„ï¼‰
            self._check_and_flush()
            
            return trade_id
            
        except Exception as e:
            logger.error(f"Error logging position entry: {e}")
            logger.exception(e)
            return None
    
    def log_position_exit(self, trade_data: Dict, binance_client=None, timeframe='1m', is_virtual=False):
        """
        è¨˜éŒ„å¹³å€‰æ™‚çš„å®Œæ•´æ­·å²æ•¸æ“šï¼Œä¸¦åˆä½µé–‹å€‰æ•¸æ“šç”Ÿæˆ ML è¨“ç·´æ¨£æœ¬
        
        Args:
            trade_data: äº¤æ˜“æ•¸æ“šå­—å…¸ï¼ŒåŒ…å«ï¼š
                - trade_id: äº¤æ˜“IDï¼ˆèˆ‡é–‹å€‰æ™‚ç›¸åŒï¼‰
                - symbol: äº¤æ˜“å°
                - exit_price: å‡ºå ´åƒ¹æ ¼
                - exit_reason: å¹³å€‰ç†ç”±
                - pnl: æç›Šï¼ˆUSDTï¼‰
                - pnl_percent: æç›Šç™¾åˆ†æ¯”
                - holding_duration_minutes: æŒå€‰æ™‚é•·ï¼ˆåˆ†é˜ï¼‰
                - entry_time: é–‹å€‰æ™‚é–“ï¼ˆç”¨æ–¼ç²å– K ç·šæ­·å²ï¼‰
                - exit_time: å¹³å€‰æ™‚é–“
                - metadata: å¹³å€‰æ™‚çš„æŠ€è¡“æŒ‡æ¨™
            binance_client: Binance å®¢æˆ¶ç«¯ï¼ˆç”¨æ–¼ç²å– K ç·šæ­·å²ï¼‰
            timeframe: æ™‚é–“æ¡†æ¶
            is_virtual: æ˜¯å¦ç‚ºè™›æ“¬å€‰ä½ï¼ˆé»˜èª Falseï¼‰
        """
        try:
            # é©—è­‰æ•¸æ“š
            is_valid, missing_fields = self.validate_exit_data(trade_data)
            if not is_valid:
                logger.error(f"Exit data validation failed, missing fields: {missing_fields}")
                return
            
            trade_id = trade_data.get('trade_id')
            
            if not trade_id:
                logger.error("Missing trade_id in exit data")
                return
            
            # æª¢æŸ¥æ˜¯å¦æœ‰å°æ‡‰çš„é–‹å€‰è¨˜éŒ„
            if trade_id not in self.pending_entries:
                logger.warning(f"âš ï¸  No entry record found for trade_id: {trade_id} - incomplete trade pair!")
                self.stats['incomplete_pairs'] += 1
                entry_record = None
            else:
                entry_record = self.pending_entries[trade_id]
            
            # é©—è­‰ä¸¦è§£ææ™‚é–“æˆ³
            entry_time = trade_data.get('entry_time')
            exit_time = trade_data.get('exit_time')
            
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½‰æ›ç‚º datetime
            if isinstance(entry_time, str):
                try:
                    entry_time = datetime.fromisoformat(entry_time.replace('Z', '+00:00'))
                except Exception as e:
                    logger.error(f"Invalid entry_time timestamp: {entry_time}, error: {e}")
                    entry_time = None
            
            if isinstance(exit_time, str):
                try:
                    exit_time = datetime.fromisoformat(exit_time.replace('Z', '+00:00'))
                except Exception as e:
                    logger.error(f"Invalid exit_time timestamp: {exit_time}, error: {e}")
                    exit_time = None
            
            # å¦‚æœæ²’æœ‰æä¾› exit_timeï¼Œä½¿ç”¨ç•¶å‰æ™‚é–“
            if exit_time is None:
                exit_time = datetime.utcnow()
            
            # ç²å–å¾é–‹å€‰åˆ°å¹³å€‰çš„å®Œæ•´ K ç·šæ­·å²
            kline_history = []
            if binance_client and entry_record and entry_time:
                try:
                    kline_history = self._fetch_kline_history(
                        binance_client,
                        trade_data.get('symbol', 'UNKNOWN'),
                        entry_time,
                        exit_time,
                        timeframe
                    )
                except Exception as e:
                    logger.warning(f"Failed to fetch kline history for {trade_data.get('symbol', 'UNKNOWN')}: {e}")
            
            # è¨ˆç®— MFE/MAEï¼ˆæœ€å¤§æœ‰åˆ©/ä¸åˆ©æ³¢å‹•ï¼‰
            entry_price = self._safe_float(entry_record.get('entry_price')) if entry_record else self._safe_float(trade_data.get('entry_price'), 0)
            entry_side = entry_record.get('side') if entry_record else trade_data.get('side', 'BUY')
            
            mfe, mae = self._calculate_mfe_mae(
                kline_history,
                entry_price,
                entry_side
            )
            
            # å¾ metadata ä¸­æå–å¹³å€‰æ™‚çš„æŠ€è¡“æŒ‡æ¨™
            exit_metadata = trade_data.get('metadata', {})
            
            # æ§‹å»ºå¹³å€‰è¨˜éŒ„
            exit_record = {
                'trade_id': trade_id,
                'timestamp': trade_data.get('exit_time', datetime.utcnow()).isoformat() if isinstance(trade_data.get('exit_time'), datetime) else trade_data.get('exit_time', datetime.utcnow().isoformat()),
                'exit_price': float(trade_data.get('exit_price', 0.0)),
                'exit_reason': trade_data.get('exit_reason', 'UNKNOWN'),
                'pnl': float(trade_data.get('pnl', 0.0)),
                'pnl_percent': float(trade_data.get('pnl_percent', 0.0)),
                'holding_duration_minutes': float(trade_data.get('holding_duration_minutes', 0.0)),
                'is_virtual': is_virtual,
                
                # å¾é–‹å€‰åˆ°å¹³å€‰çš„å®Œæ•´ K ç·šæ­·å²
                'kline_history': kline_history,
                
                # å¹³å€‰æ™‚çš„æŠ€è¡“æŒ‡æ¨™
                'exit_features': {
                    'macd': self._safe_float(exit_metadata.get('macd')),
                    'macd_signal': self._safe_float(exit_metadata.get('macd_signal')),
                    'ema_9': self._safe_float(exit_metadata.get('ema_9')),
                    'ema_21': self._safe_float(exit_metadata.get('ema_21')),
                    'ema_50': self._safe_float(exit_metadata.get('ema_50')),
                    'ema_200': self._safe_float(exit_metadata.get('ema_200')),
                    'atr': self._safe_float(exit_metadata.get('atr')),
                    'rsi': self._safe_float(exit_metadata.get('rsi')),
                },
                
                # äº¤æ˜“æ¨™ç±¤ï¼ˆä¾› XGBoost å­¸ç¿’ï¼‰
                'ml_label': {
                    'outcome': 'WIN' if trade_data.get('pnl', 0.0) > 0 else 'LOSS',
                    'pnl_percent': float(trade_data.get('pnl_percent', 0.0)),
                    'max_favorable_excursion': float(mfe),
                    'max_adverse_excursion': float(mae),
                    'hit_take_profit': 'PROFIT' in trade_data.get('exit_reason', '').upper() or 'TARGET' in trade_data.get('exit_reason', '').upper(),
                    'hit_stop_loss': 'STOP' in trade_data.get('exit_reason', '').upper() or 'LOSS' in trade_data.get('exit_reason', '').upper()
                }
            }
            
            # æ›´æ–°çµ±è¨ˆ
            self.stats['total_exits'] += 1
            
            # å¦‚æœæœ‰å°æ‡‰çš„é–‹å€‰è¨˜éŒ„ï¼Œåˆä½µç”Ÿæˆå®Œæ•´çš„ ML è¨“ç·´æ¨£æœ¬
            if entry_record:
                ml_sample = self._merge_entry_exit_data(entry_record, exit_record)
                self.ml_data.append(ml_sample)
                
                # å¾æš«å­˜ä¸­ç§»é™¤
                del self.pending_entries[trade_id]
                
                # æ›´æ–°çµ±è¨ˆ
                self.stats['complete_pairs'] += 1
                self.stats['incomplete_pairs'] = len(self.pending_entries)
                
                # ç«‹å³æŒä¹…åŒ– pending_entriesï¼ˆåˆªé™¤å·²å®Œæˆçš„æ¢ç›®ï¼‰
                self.save_pending_entries()
                
                logger.info(
                    f"âœ… Logged position exit and created ML sample: {trade_id} "
                    f"(PnL: {trade_data.get('pnl_percent', 0):.2f}%, MFE: {mfe:.2f}%, MAE: {mae:.2f}%)"
                )
                
                # æª¢æŸ¥æ˜¯å¦éœ€è¦ flush
                self._check_and_flush()
            else:
                logger.warning(f"âš ï¸  No entry record for {trade_id}, ML sample not created - incomplete pair!")
            
        except Exception as e:
            logger.error(f"Error logging position exit: {e}")
            logger.exception(e)
    
    def _check_and_flush(self):
        """æª¢æŸ¥ä¸¦åœ¨éœ€è¦æ™‚åŸ·è¡Œ flush"""
        # è¨ˆæ•¸è§¸ç™¼
        if self.stats['total_entries'] % self.buffer_size == 0:
            logger.debug(f"Count-based flush triggered (every {self.buffer_size} entries)")
            self.flush()
    
    def log_trade(self, trade_data: Dict):
        """
        è¨˜éŒ„äº¤æ˜“ï¼ˆä¿æŒå‘å¾Œå…¼å®¹ï¼‰
        
        é€™å€‹æ–¹æ³•ä¿æŒåŸæœ‰çš„ç°¡å–®è¨˜éŒ„åŠŸèƒ½ï¼Œç”¨æ–¼å¿«é€Ÿè¨˜éŒ„åŸºæœ¬äº¤æ˜“ä¿¡æ¯
        """
        trade_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'symbol': trade_data.get('symbol'),
            'type': trade_data.get('type'),
            'side': trade_data.get('side'),
            'entry_price': trade_data.get('entry_price'),
            'exit_price': trade_data.get('exit_price'),
            'quantity': trade_data.get('quantity'),
            'stop_loss': trade_data.get('stop_loss'),
            'take_profit': trade_data.get('take_profit'),
            'pnl': trade_data.get('pnl'),
            'pnl_percent': trade_data.get('pnl_percent'),
            'reason': trade_data.get('reason'),
            'strategy': trade_data.get('strategy')
        }
        
        self.trades.append(trade_entry)
        self.unsaved_count += 1
        
        if self.unsaved_count >= self.buffer_size or trade_data.get('type') == 'CLOSE':
            self.save_trades()
        
        logger.info(f"Logged trade: {trade_data.get('symbol')} {trade_data.get('type')}")
    
    def check_incomplete_pairs(self) -> List[Dict]:
        """
        æª¢æŸ¥æœªé–‰åˆçš„äº¤æ˜“å°
        
        Returns:
            æœªé–‰åˆçš„äº¤æ˜“åˆ—è¡¨
        """
        incomplete = []
        
        for trade_id, entry_record in self.pending_entries.items():
            incomplete.append({
                'trade_id': trade_id,
                'symbol': entry_record.get('symbol'),
                'side': entry_record.get('side'),
                'entry_price': entry_record.get('entry_price'),
                'timestamp': entry_record.get('timestamp'),
                'age_hours': (datetime.utcnow() - datetime.fromisoformat(entry_record.get('timestamp'))).total_seconds() / 3600
            })
        
        if incomplete:
            logger.warning(f"âš ï¸  Found {len(incomplete)} incomplete trade pairs:")
            for item in incomplete:
                logger.warning(
                    f"  - {item['trade_id']}: {item['symbol']} {item['side']} @ {item['entry_price']}, "
                    f"age: {item['age_hours']:.1f}h"
                )
        
        return incomplete
    
    def _generate_trade_id(self, symbol: str, timestamp: datetime) -> str:
        """
        ç”Ÿæˆå”¯ä¸€çš„äº¤æ˜“ID
        
        Args:
            symbol: äº¤æ˜“å°
            timestamp: æ™‚é–“æˆ³
            
        Returns:
            å”¯ä¸€çš„äº¤æ˜“IDï¼ˆæ ¼å¼ï¼šSYMBOL_YYYYMMDD_HHMMSSï¼‰
        """
        return f"{symbol}_{timestamp.strftime('%Y%m%d_%H%M%S')}"
    
    def _fetch_klines_snapshot(self, binance_client, symbol: str, timeframe: str, limit: int = 20) -> List[Dict]:
        """
        ç²å– K ç·šå¿«ç…§ï¼ˆæœ€è¿‘ N æ ¹ K ç·šï¼‰
        
        Args:
            binance_client: Binance å®¢æˆ¶ç«¯
            symbol: äº¤æ˜“å°
            timeframe: æ™‚é–“æ¡†æ¶
            limit: K ç·šæ•¸é‡
            
        Returns:
            K ç·šåˆ—è¡¨
        """
        try:
            klines_df = binance_client.get_klines(symbol, timeframe, limit=limit)
            
            if klines_df is None or klines_df.empty:
                return []
            
            # è½‰æ›ç‚ºç°¡åŒ–çš„å­—å…¸æ ¼å¼
            klines = []
            for _, row in klines_df.iterrows():
                klines.append({
                    'time': row['timestamp'].isoformat() if hasattr(row['timestamp'], 'isoformat') else str(row['timestamp']),
                    'open': float(row['open']),
                    'high': float(row['high']),
                    'low': float(row['low']),
                    'close': float(row['close']),
                    'volume': float(row['volume'])
                })
            
            return klines
            
        except Exception as e:
            logger.error(f"Error fetching klines snapshot: {e}")
            return []
    
    def _fetch_kline_history(self, binance_client, symbol: str, start_time: datetime, end_time: datetime, timeframe: str) -> List[Dict]:
        """
        ç²å–å¾é–‹å€‰åˆ°å¹³å€‰çš„ K ç·šæ­·å²
        
        Args:
            binance_client: Binance å®¢æˆ¶ç«¯
            symbol: äº¤æ˜“å°
            start_time: é–‹å§‹æ™‚é–“
            end_time: çµæŸæ™‚é–“
            timeframe: æ™‚é–“æ¡†æ¶
            
        Returns:
            K ç·šåˆ—è¡¨
        """
        try:
            # è¨ˆç®—éœ€è¦å¤šå°‘æ ¹ K ç·š
            if isinstance(start_time, str):
                start_time = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
            if isinstance(end_time, str):
                end_time = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
            
            duration_minutes = (end_time - start_time).total_seconds() / 60
            
            # æ ¹æ“šæ™‚é–“æ¡†æ¶è¨ˆç®—éœ€è¦çš„ K ç·šæ•¸é‡
            timeframe_minutes = {
                '1m': 1, '3m': 3, '5m': 5, '15m': 15, '30m': 30,
                '1h': 60, '2h': 120, '4h': 240, '1d': 1440
            }
            
            interval_minutes = timeframe_minutes.get(timeframe, 1)
            limit = int(duration_minutes / interval_minutes) + 10  # åŠ  10 æ ¹ä½œç‚ºç·©è¡
            limit = min(limit, 1000)  # Binance API é™åˆ¶
            
            # ç²å– K ç·šæ•¸æ“š
            klines_df = binance_client.get_klines(symbol, timeframe, limit=limit)
            
            if klines_df is None or klines_df.empty:
                return []
            
            # éæ¿¾æ™‚é–“ç¯„åœå…§çš„ K ç·š
            klines = []
            for _, row in klines_df.iterrows():
                kline_time = row['timestamp']
                
                # ç¢ºä¿æ™‚é–“åœ¨ç¯„åœå…§
                if kline_time >= start_time and kline_time <= end_time:
                    klines.append({
                        'time': kline_time.isoformat() if hasattr(kline_time, 'isoformat') else str(kline_time),
                        'open': float(row['open']),
                        'high': float(row['high']),
                        'low': float(row['low']),
                        'close': float(row['close']),
                        'volume': float(row['volume'])
                    })
            
            return klines
            
        except Exception as e:
            logger.error(f"Error fetching kline history: {e}")
            return []
    
    def _calculate_mfe_mae(self, kline_history: List[Dict], entry_price: float, side: str) -> tuple:
        """
        è¨ˆç®—æœ€å¤§æœ‰åˆ©æ³¢å‹•ï¼ˆMFEï¼‰å’Œæœ€å¤§ä¸åˆ©æ³¢å‹•ï¼ˆMAEï¼‰
        
        Args:
            kline_history: K ç·šæ­·å²
            entry_price: å…¥å ´åƒ¹æ ¼
            side: 'BUY' or 'SELL'
            
        Returns:
            (mfe_percent, mae_percent)
        """
        # æ·»åŠ å®Œæ•´çš„ä¿è­·æª¢æŸ¥
        if not kline_history:
            logger.debug("Empty kline_history, returning (0.0, 0.0) for MFE/MAE")
            return (0.0, 0.0)
        
        if not entry_price or entry_price == 0:
            logger.warning(f"Invalid entry_price: {entry_price}, returning (0.0, 0.0) for MFE/MAE")
            return (0.0, 0.0)
        
        if not side or side not in ['BUY', 'SELL']:
            logger.warning(f"Invalid entry_side: {side}, returning (0.0, 0.0) for MFE/MAE")
            return (0.0, 0.0)
        
        try:
            max_favorable = 0.0
            max_adverse = 0.0
            
            for kline in kline_history:
                try:
                    high = float(kline.get('high', 0))
                    low = float(kline.get('low', 0))
                    
                    # è·³éç„¡æ•ˆçš„ K ç·š
                    if high == 0 or low == 0:
                        continue
                    
                    if side == 'BUY':
                        # åšå¤šï¼šhigh æ˜¯æœ‰åˆ©æ–¹å‘ï¼Œlow æ˜¯ä¸åˆ©æ–¹å‘
                        favorable = (high - entry_price) / entry_price * 100 if entry_price > 0 else 0.0
                        adverse = (low - entry_price) / entry_price * 100 if entry_price > 0 else 0.0
                    else:  # SELL
                        # åšç©ºï¼šlow æ˜¯æœ‰åˆ©æ–¹å‘ï¼Œhigh æ˜¯ä¸åˆ©æ–¹å‘
                        favorable = (entry_price - low) / entry_price * 100 if entry_price > 0 else 0.0
                        adverse = (entry_price - high) / entry_price * 100 if entry_price > 0 else 0.0
                    
                    max_favorable = max(max_favorable, favorable)
                    max_adverse = min(max_adverse, adverse)
                    
                except (ValueError, TypeError, KeyError) as e:
                    logger.debug(f"Skipping invalid kline in MFE/MAE calculation: {e}")
                    continue
            
            return (max_favorable, max_adverse)
            
        except Exception as e:
            logger.error(f"Error calculating MFE/MAE: {e}")
            return (0.0, 0.0)
    
    def _merge_entry_exit_data(self, entry_data: Dict, exit_data: Dict) -> Dict:
        """
        åˆä½µé–‹å€‰å’Œå¹³å€‰æ•¸æ“šæˆå®Œæ•´çš„ ML è¨“ç·´æ¨£æœ¬
        
        Args:
            entry_data: é–‹å€‰æ•¸æ“š
            exit_data: å¹³å€‰æ•¸æ“š
            
        Returns:
            å®Œæ•´çš„ ML è¨“ç·´æ¨£æœ¬
        """
        return {
            **entry_data,
            'exit': exit_data,
            'ml_ready': True,
            'created_at': datetime.utcnow().isoformat()
        }
    
    def _sanitize_metadata(self, metadata):
        """
        æ¸…ç† metadataï¼Œç¢ºä¿å¯ä»¥åºåˆ—åŒ–ç‚º JSON
        
        è™•ç†å„ç¨®ä¸èƒ½ç›´æ¥åºåˆ—åŒ–ç‚º JSON çš„å°è±¡ï¼š
        - NumPy æ¨™é‡ï¼ˆnp.int64, np.float64 ç­‰ï¼‰â†’ Python float/int
        - pandas Timestamps â†’ ISO å­—ç¬¦ä¸²
        - NaN/inf â†’ None
        - NumPy æ•¸çµ„ã€pandas Series â†’ Python åˆ—è¡¨
        - è‡ªå®šç¾©å°è±¡ â†’ å­—ç¬¦ä¸²è¡¨ç¤º
        
        Args:
            metadata: è¦æ¸…ç†çš„æ•¸æ“šï¼ˆå¯ä»¥æ˜¯ä»»ä½•é¡å‹ï¼‰
            
        Returns:
            å¯ä»¥åºåˆ—åŒ–ç‚º JSON çš„æ•¸æ“š
        """
        try:
            import numpy as np
            import pandas as pd
            
            # éæ­¸è™•ç†å­—å…¸
            if isinstance(metadata, dict):
                return {k: self._sanitize_metadata(v) for k, v in metadata.items()}
            
            # éæ­¸è™•ç†åˆ—è¡¨å’Œå…ƒçµ„
            elif isinstance(metadata, (list, tuple)):
                return [self._sanitize_metadata(item) for item in metadata]
            
            # NumPy æ•´æ•¸é¡å‹
            elif isinstance(metadata, np.integer):
                return int(metadata)
            
            # NumPy æµ®é»é¡å‹ï¼ˆæª¢æŸ¥ NaNï¼‰
            elif isinstance(metadata, np.floating):
                if np.isnan(metadata):
                    return None
                return float(metadata)
            
            # NumPy æ•¸çµ„å’Œ pandas Series
            elif isinstance(metadata, (np.ndarray, pd.Series)):
                return [self._sanitize_metadata(x) for x in metadata.tolist()]
            
            # pandas Timestamp
            elif isinstance(metadata, pd.Timestamp):
                return metadata.isoformat()
            
            # Python floatï¼ˆæª¢æŸ¥ NaN å’Œ infï¼‰
            elif isinstance(metadata, float):
                if np.isnan(metadata) or np.isinf(metadata):
                    return None
                return metadata
            
            # Python int
            elif isinstance(metadata, int):
                return metadata
            
            # å­—ç¬¦ä¸²ã€å¸ƒçˆ¾å€¼ã€None
            elif isinstance(metadata, (str, bool, type(None))):
                return metadata
            
            # datetime å°è±¡
            elif isinstance(metadata, datetime):
                return metadata.isoformat()
            
            # å…¶ä»–ä¸å¯åºåˆ—åŒ–çš„å°è±¡ â†’ è½‰ç‚ºå­—ç¬¦ä¸²
            else:
                logger.debug(f"Converting unknown type {type(metadata)} to string: {metadata}")
                return str(metadata)
                
        except Exception as e:
            logger.warning(f"Error sanitizing metadata: {e}, returning string representation")
            return str(metadata)
    
    def _safe_float(self, value, default=None) -> Optional[float]:
        """
        å®‰å…¨åœ°è½‰æ›ç‚º floatï¼Œè™•ç† NaN/None å€¼
        
        Args:
            value: è¦è½‰æ›çš„å€¼
            default: é»˜èªå€¼ï¼ˆå¦‚æœè½‰æ›å¤±æ•—ï¼‰
            
        Returns:
            float æˆ– None
        """
        try:
            if value is None:
                return default
            
            f = float(value)
            
            # æª¢æŸ¥æ˜¯å¦ç‚º NaN
            if f != f:  # NaN ä¸ç­‰æ–¼è‡ªå·±
                return default
            
            return f
        except (ValueError, TypeError):
            return default
    
    def _calculate_distance_from_ema200(self, current_price, ema_200) -> Optional[float]:
        """è¨ˆç®—åƒ¹æ ¼èˆ‡ EMA200 çš„è·é›¢"""
        if current_price is None or ema_200 is None:
            return None
        
        try:
            return float(current_price) - float(ema_200)
        except (ValueError, TypeError):
            return None
    
    def _calculate_distance_from_ema200_pct(self, current_price, ema_200) -> Optional[float]:
        """è¨ˆç®—åƒ¹æ ¼èˆ‡ EMA200 çš„è·é›¢ç™¾åˆ†æ¯”"""
        if current_price is None or ema_200 is None or float(ema_200) == 0:
            return None
        
        try:
            return (float(current_price) - float(ema_200)) / float(ema_200) * 100
        except (ValueError, TypeError, ZeroDivisionError):
            return None
    
    def flush(self):
        """å¼·åˆ¶ä¿å­˜æ‰€æœ‰æœªä¿å­˜çš„æ•¸æ“š"""
        logger.info("ğŸ”„ Flushing all data to disk...")
        
        # æª¢æŸ¥æœªé–‰åˆçš„äº¤æ˜“
        incomplete = self.check_incomplete_pairs()
        if incomplete:
            logger.warning(f"âš ï¸  Warning: {len(incomplete)} incomplete trade pairs will be persisted")
        
        # ä¿å­˜æ‰€æœ‰æ•¸æ“š
        if self.unsaved_count > 0:
            self.save_trades()
        
        if len(self.ml_data) > 0:
            self.save_ml_data()
        
        # ä¿å­˜å¾…è™•ç†çš„é–‹å€‰è¨˜éŒ„
        self.save_pending_entries()
        
        # æ›´æ–°çµ±è¨ˆ
        self.stats['total_flushes'] += 1
        self.stats['last_flush_timestamp'] = datetime.utcnow().isoformat()
        self.last_flush_time = time.time()
        
        logger.info(
            f"âœ… Flush complete: "
            f"trades={len(self.trades)}, "
            f"ml_samples={len(self.ml_data)}, "
            f"pending_entries={len(self.pending_entries)}"
        )
    
    def get_recent_trades(self, limit: int = 10) -> List[Dict]:
        """ç²å–æœ€è¿‘çš„äº¤æ˜“"""
        return self.trades[-limit:]
    
    def get_trades_by_symbol(self, symbol: str) -> List[Dict]:
        """ç²å–ç‰¹å®šäº¤æ˜“å°çš„äº¤æ˜“è¨˜éŒ„"""
        return [trade for trade in self.trades if trade['symbol'] == symbol]
    
    def get_statistics(self) -> Dict:
        """
        ç²å–å®Œæ•´çš„çµ±è¨ˆä¿¡æ¯
        
        Returns:
            çµ±è¨ˆä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ï¼š
            - ç¸½æ¨£æœ¬æ•¸
            - å®Œæ•´/ä¸å®Œæ•´äº¤æ˜“å°æ•¸é‡
            - ç‰¹å¾µè¦†è“‹ç‡
            - ML è¨“ç·´æ•¸æ“šçµ±è¨ˆ
        """
        ml_stats = self.get_ml_statistics()
        
        return {
            'data_integrity': {
                'total_entries': self.stats['total_entries'],
                'total_exits': self.stats['total_exits'],
                'complete_pairs': self.stats['complete_pairs'],
                'incomplete_pairs': self.stats['incomplete_pairs'],
                'pair_completion_rate': (self.stats['complete_pairs'] / self.stats['total_entries'] * 100) if self.stats['total_entries'] > 0 else 0
            },
            'ml_training_data': ml_stats,
            'feature_coverage': self.stats.get('feature_coverage', {}),
            'data_quality': {
                'validation_errors': self.stats['validation_errors'],
                'total_flushes': self.stats['total_flushes'],
                'last_flush': self.stats.get('last_flush_timestamp', 'Never')
            }
        }
    
    def get_ml_statistics(self) -> Dict:
        """
        ç²å– ML è¨“ç·´æ•¸æ“šçµ±è¨ˆ
        
        Returns:
            çµ±è¨ˆä¿¡æ¯å­—å…¸
        """
        if not self.ml_data:
            return {
                'total_samples': 0,
                'winning_samples': 0,
                'losing_samples': 0,
                'win_rate': 0,
                'avg_mfe': 0,
                'avg_mae': 0,
                'avg_holding_time': 0
            }
        
        winning = sum(1 for sample in self.ml_data if sample['exit']['ml_label']['outcome'] == 'WIN')
        losing = len(self.ml_data) - winning
        
        avg_mfe = sum(sample['exit']['ml_label']['max_favorable_excursion'] for sample in self.ml_data) / len(self.ml_data)
        avg_mae = sum(sample['exit']['ml_label']['max_adverse_excursion'] for sample in self.ml_data) / len(self.ml_data)
        avg_holding = sum(sample['exit']['holding_duration_minutes'] for sample in self.ml_data) / len(self.ml_data)
        
        return {
            'total_samples': len(self.ml_data),
            'winning_samples': winning,
            'losing_samples': losing,
            'win_rate': (winning / len(self.ml_data) * 100) if len(self.ml_data) > 0 else 0,
            'avg_mfe': avg_mfe,
            'avg_mae': avg_mae,
            'avg_holding_time': avg_holding
        }
    
    def calculate_statistics(self) -> Dict:
        """è¨ˆç®—äº¤æ˜“çµ±è¨ˆæ•¸æ“šï¼ˆä¿æŒå‘å¾Œå…¼å®¹ï¼‰"""
        if not self.trades:
            return {
                'total_trades': 0,
                'winning_trades': 0,
                'losing_trades': 0,
                'win_rate': 0,
                'total_profit': 0,
                'average_profit': 0,
                'best_trade': 0,
                'worst_trade': 0
            }
        
        total_trades = len(self.trades)
        winning_trades = sum(1 for trade in self.trades if trade.get('pnl', 0) > 0)
        losing_trades = sum(1 for trade in self.trades if trade.get('pnl', 0) < 0)
        
        total_profit = sum(trade.get('pnl', 0) for trade in self.trades)
        average_profit = total_profit / total_trades if total_trades > 0 else 0
        
        pnls = [trade.get('pnl', 0) for trade in self.trades]
        best_trade = max(pnls) if pnls else 0
        worst_trade = min(pnls) if pnls else 0
        
        win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0
        
        return {
            'total_trades': total_trades,
            'winning_trades': winning_trades,
            'losing_trades': losing_trades,
            'win_rate': win_rate,
            'total_profit': total_profit,
            'average_profit': average_profit,
            'best_trade': best_trade,
            'worst_trade': worst_trade
        }
